{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7500c655-c9b9-4ed3-a6cb-b4cf20861bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b225a2c7-0231-4225-8dec-efe5c9d12b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Global\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Global\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Global\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bb27a0-cd5f-480b-a276-da6530afa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (replace the file paths with your dataset location)\n",
    "train_data = pd.read_csv(\"new_train_data_s140.csv\", encoding='ISO-8859-1')\n",
    "test_data = pd.read_csv(\"new_test_data_s140.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72486529-8c51-4cd4-9e78-8b267826e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for easier access\n",
    "columns = ['Polarity', 'Id', 'Date', 'Query', 'User', 'Text']\n",
    "train_data.columns = columns\n",
    "test_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59db1b98-5d17-4f32-9dcb-4cae9870226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "combined_data = combined_data.drop(['Id', 'Date', 'Query', 'User'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8afa0a5-de97-4f19-b877-40cc337bf45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data Shape: (1600494, 2)\n",
      "Null values in Train Data:\n",
      " Polarity    0\n",
      "Id          0\n",
      "Date        0\n",
      "Query       0\n",
      "User        0\n",
      "Text        0\n",
      "dtype: int64\n",
      "Null values in Test Data:\n",
      " Polarity    0\n",
      "Id          0\n",
      "Date        0\n",
      "Query       0\n",
      "User        0\n",
      "Text        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the combined dataset\n",
    "print(\"Combined Data Shape:\", combined_data.shape)\n",
    "\n",
    "# Check for null values\n",
    "print(\"Null values in Train Data:\\n\", train_data.isnull().sum())\n",
    "print(\"Null values in Test Data:\\n\", test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400a3532-8171-47ff-96c4-c80b21a98bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    # Remove URLs, mentions, hashtags\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization (reduce words to their base form)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    clean_text = ' '.join(lemmatized_text)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b30bc82d-906a-43f3-8394-9ae399c0c383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  @Kenichan I dived many times for the ball. Man...   \n",
      "1    my whole body feels itchy and like its on fire    \n",
      "2  @nationwideclass no, it's not behaving at all....   \n",
      "3                      @Kwesidei not the whole crew    \n",
      "4                                        Need a hug    \n",
      "\n",
      "                                        Clean_Text  \n",
      "0  dived many time ball managed save rest go bound  \n",
      "1                  whole body feel itchy like fire  \n",
      "2                         behaving im mad cant see  \n",
      "3                                       whole crew  \n",
      "4                                         need hug  \n"
     ]
    }
   ],
   "source": [
    "# Apply text cleaning to both training and testing datasets\n",
    "train_data['Clean_Text'] = train_data['Text'].apply(clean_text)\n",
    "test_data['Clean_Text'] = test_data['Text'].apply(clean_text)\n",
    "\n",
    "# Check the cleaned data\n",
    "print(train_data[['Text', 'Clean_Text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb742269-a0dd-4002-8dc6-3573299c182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset for training\n",
    "X = train_data['Clean_Text']  # Features (cleaned text)\n",
    "y = train_data['Polarity']    # Target (sentiment polarity)\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit the number of features for simplicity\n",
    "\n",
    "# Fit the vectorizer on training data and transform both train and validation sets\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "\n",
    "# Check the TF-IDF matrix\n",
    "print(\"TF-IDF train matrix shape:\", X_train_tfidf.shape)\n",
    "print(\"TF-IDF validation matrix shape:\", X_val_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378a584-129d-497f-bdef-2ec122db2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58d8b6-a73a-4823-8ef5-28ee67b9e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "# Create a heatmap visualization\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a45ce-f571-41e3-ae12-c945c258e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Get the predicted probabilities for the positive class\n",
    "y_prob = model.predict_proba(X_val_tfidf)[:, 1]\n",
    "\n",
    "# Compute ROC curve and AUC, setting pos_label to 4\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_prob, pos_label=4)\n",
    "auc_score = roc_auc_score(y_val, y_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391bbf94-b6bb-4fd7-82df-9d2a1215e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Compute Precision-Recall curve, specifying the positive class\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_prob, pos_label=4)\n",
    "\n",
    "# Plot the Precision-Recall curve\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a68b8-8a9c-4b46-9b69-61bb134d16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get the classification report as a dictionary\n",
    "report = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "# Extract precision, recall, and f1-score for each class\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "classes = model.classes_\n",
    "\n",
    "# Plot the metrics for each class\n",
    "for metric in metrics:\n",
    "    values = [report[str(cls)][metric] for cls in classes]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.bar(classes, values, color='skyblue')\n",
    "    plt.title(f'{metric.capitalize()} per Class')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
