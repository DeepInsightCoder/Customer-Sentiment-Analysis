{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c233d890-388b-43fb-ad8a-fdc54c43369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the preprocessed datasets\n",
    "sentiment140_data = pd.read_csv('cleaned_sentiment140_data.csv')\n",
    "trustpilot_reviews_data = pd.read_csv('cleaned_trustpilot_reviews_data.csv')\n",
    "twitter_data = pd.read_csv('cleaned_twitter_data.csv')\n",
    "reviews_data = pd.read_csv('cleaned_reviews_data.csv')\n",
    "ratings_beauty_data = pd.read_csv('cleaned_ratings_beauty_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0ecba6-9541-4c29-a6ae-f6687240695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Data:\n",
      "   Polarity            Id                          Date     Query      User  \\\n",
      "0       0.0  1.467811e+09  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY  mattycus   \n",
      "1       0.0  1.467811e+09  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   ElleCTF   \n",
      "2       0.0  1.467811e+09  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY    Karoli   \n",
      "3       0.0  1.467811e+09  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY  joy_wolf   \n",
      "4       0.0  1.467812e+09  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   mybirch   \n",
      "\n",
      "                                                Text sentiment name  \\\n",
      "0  @Kenichan I dived many times for the ball. Man...   neutral  NaN   \n",
      "1    my whole body feels itchy and like its on fire    neutral  NaN   \n",
      "2  @nationwideclass no, it's not behaving at all....   neutral  NaN   \n",
      "3                      @Kwesidei not the whole crew    neutral  NaN   \n",
      "4                                        Need a hug    neutral  NaN   \n",
      "\n",
      "  company_url trustpilot_url  ... ProductId UserId ProfileName  \\\n",
      "0         NaN            NaN  ...       NaN    NaN         NaN   \n",
      "1         NaN            NaN  ...       NaN    NaN         NaN   \n",
      "2         NaN            NaN  ...       NaN    NaN         NaN   \n",
      "3         NaN            NaN  ...       NaN    NaN         NaN   \n",
      "4         NaN            NaN  ...       NaN    NaN         NaN   \n",
      "\n",
      "  HelpfulnessNumerator  HelpfulnessDenominator Score Time Summary  Rating  \\\n",
      "0                  NaN                     NaN   NaN  NaN     NaN     NaN   \n",
      "1                  NaN                     NaN   NaN  NaN     NaN     NaN   \n",
      "2                  NaN                     NaN   NaN  NaN     NaN     NaN   \n",
      "3                  NaN                     NaN   NaN  NaN     NaN     NaN   \n",
      "4                  NaN                     NaN   NaN  NaN     NaN     NaN   \n",
      "\n",
      "  Timestamp  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2       NaN  \n",
      "3       NaN  \n",
      "4       NaN  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine all datasets into one\n",
    "combined_data = pd.concat([sentiment140_data, trustpilot_reviews_data, twitter_data, reviews_data, ratings_beauty_data], ignore_index=True)\n",
    "\n",
    "# Display first few rows of combined data to verify\n",
    "print(\"Combined Data:\")\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10598edc-9656-4dc5-9742-af6c3ecdec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'Text': 2027268\n",
      "Missing values in 'Text' after filling: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the 'Text' column\n",
    "missing_text_count = combined_data['Text'].isnull().sum()\n",
    "print(f\"Missing values in 'Text': {missing_text_count}\")\n",
    "# Drop rows where 'Text' is NaN\n",
    "combined_data.dropna(subset=['Text'], inplace=True)\n",
    "# Fill missing values with an empty string\n",
    "combined_data['Text'].fillna('', inplace=True)\n",
    "# Verify the number of missing values again\n",
    "print(f\"Missing values in 'Text' after filling: {combined_data['Text'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aa715f-dfbb-4d3a-bc67-f21b28419890",
   "metadata": {},
   "source": [
    "# Feature Extraction Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193d5f66-cd97-407c-b0aa-e31e9ff4c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into numerical data\n",
    "tfidf = TfidfVectorizer(max_features=5000) \n",
    "X = tfidf.fit_transform(combined_data['Text'])\n",
    "y = combined_data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db54cf8a-870f-48ba-b516-65662f3cd53b",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049ac507-d989-4f9f-bb24-1633e5d660ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d26f4d9b-27d6-4472-96be-64ed67cc136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bf7e77-7133-44b8-8df6-6277d737a1ec",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866b36b8-9940-488c-9ec4-12ff71986962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1 Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4dc4c1-4d11-4f3b-a2b4-77a77d4575ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.65      0.74     11715\n",
      "     neutral       0.99      0.99      0.99    321979\n",
      "    positive       0.95      0.98      0.96     99997\n",
      "\n",
      "    accuracy                           0.98    433691\n",
      "   macro avg       0.94      0.87      0.90    433691\n",
      "weighted avg       0.98      0.98      0.98    433691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ae2d8-fc89-4654-8d09-97ca9eb218e2",
   "metadata": {},
   "source": [
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d587ec4-c095-4f59-bcb1-f7b80c3dcdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'sentiment_analysis_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(model, 'sentiment_analysis_model.pkl')\n",
    "print(\"Model saved as 'sentiment_analysis_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
